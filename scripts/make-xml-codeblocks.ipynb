{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README\n",
    "\n",
    "Here I'm just doing a bit of wrangling to make different codeblocks that I need for BEAST xml files. At some point this can start to the form the basis of a broader program to fully automate xml file generation without using BEAUti. For now it just generates some chunks that BEAUti won't make right now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make generalDataType code block\n",
    "with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/indexed-countries-45.tsv','rU') as infile:\n",
    "    with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/beast/generalDataType_countryList.txt', 'w') as outfile:\n",
    "        for line in infile:\n",
    "            if line.startswith('country'):\n",
    "                continue\n",
    "            else:\n",
    "                outfile.write('\\t\\t')\n",
    "                outfile.write('<state code=\"{}\"/>'.format(line.split('\\t')[0]))\n",
    "                outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  1.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "#make markov rewards code block\n",
    "\n",
    "#link countries to an index to ensure proper ordering is preserved\n",
    "#current file ordering is correct\n",
    "index_dict = {}\n",
    "counter = 0\n",
    "with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/indexed-countries-45.tsv','rU') as infile:\n",
    "    for line in infile:\n",
    "        if line.startswith('country'):\n",
    "            continue\n",
    "        else:\n",
    "            index_dict[counter] = line.split('\\t')[0] #use country, not region\n",
    "            counter +=1\n",
    "            \n",
    "#initialize empty markov rewards matrix\n",
    "#need the same number of rows and columns as you have demes. I.E. here it needs to be 45 by 45.\n",
    "reward_matrix = np.zeros((len(index_dict),len(index_dict)))\n",
    "for i in range(len(index_dict)): #for row in matrix\n",
    "    for j in range(len(index_dict)): #for column in matrix\n",
    "        if i == j: #if indexes match, i.e. the countries are the same:\n",
    "            reward_matrix[i,j] += 1 #that markov reward entry should == 1.\n",
    "        else:\n",
    "            continue #all other entries should be 0.\n",
    "print reward_matrix\n",
    "\n",
    "reward_xml_code ='''\\t\\t\\t<parameter id=\"{country}_reward\" value=\"{values}\"/>\\n'''\n",
    "\n",
    "with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/beast/markov_rewards_block.txt', 'w') as outfile:\n",
    "    outfile.write('\\t\\t<rewards>\\n')\n",
    "    for i in range(len(reward_matrix)):\n",
    "        outfile.write(reward_xml_code.format(country=index_dict[i], values = ' '.join(str(value) for value in reward_matrix[i])))\n",
    "    outfile.write('\\t\\t</rewards>\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize empty markov rewards matrix\n",
    "#need the same number of rows and columns as you have demes. I.E. here it needs to be 45 by 45.\n",
    "count_matrix = np.zeros((len(index_dict),len(index_dict)))\n",
    "for i in range(len(index_dict)): #for row in matrix\n",
    "    for j in range(len(index_dict)): #for column in matrix\n",
    "        if i != j: #if indexes match, i.e. the countries are the same:\n",
    "            count_matrix[i,j] += 1 #that markov reward entry should == 1.\n",
    "        else:\n",
    "            continue #diagonal entries should be 0.\n",
    "values = []\n",
    "for i in range(len(count_matrix)):\n",
    "    values.append(' '.join(str(value) for value in count_matrix[i]))\n",
    "string_values =  ' '.join(values)\n",
    "#print count_matrix\n",
    "\n",
    "\n",
    "count_xml_code = '''\\t\\t<parameter id=\"country.count\" value=\"{values}\"/>\\n'''\n",
    "with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/beast/markov_countryCounts_block.txt', 'w') as outfile:\n",
    "    outfile.write(count_xml_code.format(values = string_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Below, I'm making the Markov Jump matrices. Note that these are formatted differently from how the GLM predictor matrices are formatted. Notably both the size of the matrices are different (Markov jumps matrix DO CONTAIN the diagonal values while the GLM predictor matrices do not), and the indexing is different (see figure below). \n",
    "\n",
    "**GLM Predictor indexing**\n",
    "\n",
    "XXXXXXX| usa |canada| mexico\n",
    "-------|-----|-------|-------\n",
    "usa    |XXXXX|  0    | 1\n",
    "canada |3    |XXXXXXX| 2\n",
    "mexico |4    |  5    | XXXXXX\n",
    "\n",
    "**Markov jump matrix indexing**\n",
    "\n",
    "XXXXXXX| usa |canada| mexico\n",
    "-------|-----|-------|-------\n",
    "usa    |0    |  1    | 2\n",
    "canada |3    |  4    | 5\n",
    "mexico |6    |  7    | 8\n",
    "\n",
    "The markov jump matrices are made for both `to_<country>` and `from_<country>` for all countries that you want Markov jumps for. The matrices contain values of 1 for all instances where you are going to/from the indicated countries. All other values in the matrix, including diagonals (to and from country are the same country), get a value of 0.\n",
    "\n",
    "To make sure that the code is working properly I've 'remade' the jump matrices for `AC1_to` and `AC1_from` from Lemey et al (2014) paper Unifying Viral Genetics and Human Transportation Data to Predict the Global Transmission Dynamics of Human Influenza H3N2. The xml is available as part of the supplement online. Here I'm making the matries and then seeing if I can find them in the xml, ensuring they match what I think they should.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "counter2 = 0\n",
    "lemey_states = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "lemey_dict = {}\n",
    "for from_state in lemey_states: #from_states represent rows in the matrix\n",
    "    for to_state in lemey_states: #to_states represent columns in the matrix\n",
    "        lemey_dict[counter2] = (from_state,to_state)\n",
    "        counter2 +=1\n",
    "\n",
    "ac1_to = []\n",
    "for key in lemey_dict.keys():\n",
    "    if lemey_dict[key][1] == 1 and lemey_dict[key][0] != lemey_dict[key][1]: #if second value in tuple, i.e. the 'to' country, is canada\n",
    "        ac1_to.append(1)\n",
    "    else:\n",
    "        ac1_to.append(0)\n",
    "\n",
    "ac1_to_xml = ' '.join(str(value) for value in ac1_to)\n",
    "print ac1_to_xml\n",
    "\n",
    "ac1_from = []\n",
    "for key in lemey_dict.keys():\n",
    "    if lemey_dict[key][0] == 1 and lemey_dict[key][0] != lemey_dict[key][1]: #if second value in tuple, i.e. the 'to' country, is canada\n",
    "        ac1_from.append(1)\n",
    "    else:\n",
    "        ac1_from.append(0)\n",
    "\n",
    "ac1_from_xml = ' '.join(str(value) for value in ac1_from)\n",
    "print ac1_from_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['canada', 'united_states', 'bermuda', 'mexico', 'belize', 'guatemala', 'honduras', 'el_salvador', 'nicaragua', 'costa_rica', 'panama', 'bahamas', 'cuba', 'turks_caicos_islands', 'cayman_islands', 'jamaica', 'haiti', 'dominican_republic', 'puerto_rico', 'united_states_virgin_islands', 'saint_kitts_nevis', 'antigua_barbuda', 'guadeloupe', 'dominica', 'martinique', 'saint_lucia', 'saint_vincent_grenadines', 'barbados', 'grenada', 'trinidad_tobago', 'curacao', 'aruba', 'french_guiana', 'suriname', 'guyana', 'venezuela', 'colombia', 'ecuador', 'peru', 'bolivia', 'brazil', 'paraguay', 'uruguay', 'argentina', 'chile']\n",
      "\n",
      " 45 countries included in analysis\n",
      "2025\n",
      "2025\n",
      "2025\n",
      "2025\n"
     ]
    }
   ],
   "source": [
    "# Lemey et al predictors look good. Moving on to my predictors now\n",
    "with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/indexed-countries-45.tsv') as file:\n",
    "    countries_list = [line.strip().split('\\t')[0] for line in file if not line.startswith('country')]\n",
    "    \n",
    "print countries_list #this should be ordered north to south\n",
    "print '\\n {} countries included in analysis'.format(len(countries_list)) #this should be 45\n",
    "\n",
    "countries_dict = {}\n",
    "count_ints = 0\n",
    "for from_state in countries_list:\n",
    "    for to_state in countries_list:\n",
    "        countries_dict[count_ints] = (from_state,to_state) #tuple[0] == from_state, tuple[1] == to_state\n",
    "        count_ints +=1\n",
    "\n",
    "print len(countries_dict)\n",
    "assert len(countries_dict) == len(countries_list)**2, 'markov jump matrix wrong size, check that diagonals are being included'\n",
    "\n",
    "to_usvi_list = []\n",
    "from_usvi_list = []\n",
    "\n",
    "#from usvi list, from_states is tuple[0]\n",
    "for key in countries_dict.keys():\n",
    "    if countries_dict[key][0] == 'united_states_virgin_islands' and countries_dict[key][0] != countries_dict[key][1]: #from country is usvi, to country is different\n",
    "        from_usvi_list.append(1)\n",
    "    else:\n",
    "        from_usvi_list.append(0)\n",
    "\n",
    "#to usvi list, to_states is tuple[1]\n",
    "for key in countries_dict.keys():\n",
    "    if countries_dict[key][1] == 'united_states_virgin_islands' and countries_dict[key][0] != countries_dict[key][1]: #to country is usvi, from country is different\n",
    "        to_usvi_list.append(1)\n",
    "    else:\n",
    "        to_usvi_list.append(0)\n",
    "\n",
    "print 45**2\n",
    "print len(to_usvi_list)\n",
    "print len(from_usvi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xml_jump_code ='''\\t\\t<parameter id=\"{}_usvi\" value=\"{values}\"/>\\n'''\n",
    "with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/beast/markov_jumps_block.txt', 'w') as outfile:\n",
    "    outfile.write(xml_jump_code.format('to', values = ' '.join(str(value) for value in to_usvi_list)))\n",
    "    outfile.write(xml_jump_code.format('from', values = ' '.join(str(value) for value in from_usvi_list)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

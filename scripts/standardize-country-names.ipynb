{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'm working to standardize data downloads. Inputs to this notebook are the data in whatever form they can be downloaded as (these raw files are kept in the `raw-data` directory. Output of this notebook are tsv files in the form of `country \\t quantity`. Names are outputted in their canonical snakecase form, but non-Americas countries are _not_ trimmed out at this point.\n",
    "\n",
    "Raw data files that need standardization are:\n",
    "\n",
    "* `americas-zika-suitability.tsv` (Messina et al Zika environmental suitability scores output from Mathematica notebook)\n",
    "* `Americas-to-Americas-2012-2016_KK_DB.xlsx` (Datafile made available from Kamran Kahn)\n",
    "* `pop-weighted-centroids.tsv` (Population weighted centroids for each country, output from Mathematica)\n",
    "* `proportion-urban-population-worldbank.csv` (Proportion of population living in an urban area, direct download from WorldBank)\n",
    "* `raw-cia-world-factbook-pop-sizes.txt` (Country population size, direct download from CIA world factbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define naming conversion function\n",
    "def camelcase_to_snakecase(name):\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower().replace(' ','').replace('-','').replace(',_the','').replace('andthe_','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CIA world factbook download is particularly bad. Commas, weird white space, and other annoying formatting, so dealing with this\n",
    "#one on its own first.\n",
    "raw_popsize_file = '/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/raw-data/raw-cia-world-factbook-pop-sizes.txt'\n",
    "popsize_dict = {}\n",
    "with open(raw_popsize_file,'r') as file:\n",
    "    for line in file:\n",
    "        line = line.replace(',','').replace(' ','')\n",
    "        country = re.findall('\\d+|\\D+', line)[1]\n",
    "        snakecase_country = camelcase_to_snakecase(country)\n",
    "        pop_size = re.findall('\\d+|\\D+', line)[2]\n",
    "        popsize_dict[snakecase_country] = pop_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this fixes the whitespace issues, and fixes almost all the names, with the exception of the `virgin_islands` which should be `united_states_virgin_islands`. I'll fix that below using my name fix tsv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load in raw datasets as dataframes\n",
    "#at this point only the popsize_df has the names in the correct format, others are fixed below.\n",
    "popsize_df = pd.DataFrame(list(popsize_dict.iteritems()), columns=['country','population_size'])\n",
    "\n",
    "pop_weighted_centroids_df = pd.read_csv('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/raw-data/pop-weighted-centroids.tsv', sep='\\t', names=['country','latitude','longitude'])\n",
    "\n",
    "suitability_df = pd.read_csv('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/raw-data/americas-zika-suitability.tsv', sep='\\t',names=['Country','suitability_score'])\n",
    "\n",
    "pax_traffic_df = pd.read_excel('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/raw-data/Americas-to-Americas-2012-2016_KK_DB.xlsx')\n",
    "pax_traffic_df.columns = ['pax_volume','originCamelCase','destinationCamelCase','year']\n",
    "\n",
    "urban_pop_df = pd.read_csv('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/raw-data/proportion-urban-population-worldbank.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Standardize Country Naming for Suitability, Passenger Air (PAX traffic) and Urban proportion of population dataframes #####\n",
    "\n",
    "#Switch names to snake_case with the above function. This will fix most country names, but not all.\n",
    "pax_traffic_df['origin'] = pax_traffic_df['originCamelCase'].apply(camelcase_to_snakecase)\n",
    "pax_traffic_df['destination'] = pax_traffic_df['destinationCamelCase'].apply(camelcase_to_snakecase)\n",
    "urban_pop_df['Country Name'] = urban_pop_df['Country Name'].apply(camelcase_to_snakecase)\n",
    "suitability_df['Country'] = suitability_df['Country'].apply(camelcase_to_snakecase)\n",
    "pop_weighted_centroids_df['country'] = pop_weighted_centroids_df['country'].apply(camelcase_to_snakecase)\n",
    "#To switch the remaining, more problematic names, I'm going to use a name fix tsv file.\n",
    "\n",
    "#read in name fix tsv, making a dictionary where the key is the name in it's messed up form, and the value \n",
    "#is the standardized name in the form I want.\n",
    "name_fix_df = pd.read_table('/Users/alliblk/Desktop/gitrepos/zika-usvi/scripts/name_fix.tsv',sep='\\t')\n",
    "name_fix_dict = dict(name_fix_df.values)\n",
    "# make a new column to hold the standardized names\n",
    "# note that I'm not fixing any messed up names of countries that are not part of our analysis.\n",
    "# eg bosniaand_herzegovina should be left as is since it's not part of the analysis.\n",
    "# therefore if name_fix_dict.get() is None I want the same (messed up) row name to be returned.\n",
    "# all of this will be saved as a new series and appended to the df.\n",
    "# note axis = 1 just says loop through the rows.\n",
    "\n",
    "popsize_df['country'] = popsize_df.apply(lambda row: name_fix_dict.get(row['country'],row['country']), axis=1)\n",
    "pop_weighted_centroids_df['country'] = pop_weighted_centroids_df.apply(lambda row: name_fix_dict.get(row['country'],row['country']), axis=1)\n",
    "urban_pop_df['country'] = urban_pop_df.apply(lambda row: name_fix_dict.get(row['Country Name'],row['Country Name']),axis=1)\n",
    "pax_traffic_df['origin'] = pax_traffic_df.apply(lambda row: name_fix_dict.get(row['origin'],row['origin']),axis=1)\n",
    "pax_traffic_df['destination'] = pax_traffic_df.apply(lambda row: name_fix_dict.get(row['destination'],row['destination']),axis=1)\n",
    "suitability_df['country'] = suitability_df.apply(lambda row: name_fix_dict.get(row['Country'],row['Country']), axis=1)\n",
    "\n",
    "##### for Urban Population, turn percent (0 to 100 scale) to fraction (0 to 1 scale). Using the 2016 urban proportion data.\n",
    "urban_pop_df['2016_urban_pop_fraction'] = urban_pop_df['2016']/100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Alright, so we've fixed up the raw data frames nicely. Export to tsv.\n",
    "pop_weighted_centroids_df.to_csv('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/standardized-data/std-population-weighted-centroids.tsv', index = False, columns = ['country', 'latitude','longitude'], sep = '\\t')\n",
    "popsize_df.to_csv('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/standardized-data/std-population-size.tsv', index = False, columns = ['country', 'population_size'], sep = '\\t')\n",
    "suitability_df.to_csv('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/standardized-data/std-zika-suitability.tsv', index = False, columns = ['country', 'suitability_score'], sep = '\\t')\n",
    "pax_traffic_df.to_csv('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/standardized-data/std-pax-volume.tsv', index=False, columns = ['origin', 'destination' , 'pax_volume'], sep = '\\t')\n",
    "urban_pop_df.to_csv('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/glm/standardized-data/std-urban-pop-fraction.tsv', index=False, columns = ['country','2016_urban_pop_fraction'], sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

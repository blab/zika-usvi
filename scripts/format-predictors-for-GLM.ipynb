{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_countries = ['united_states','canada','mexico']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once linearized, the 1D predictor matrix should be length_matrix times length_matrix - 1 long. This is because the diagonal values (eg canada to canada) are removed from the linearized matrix before it is put in the xml. Thus, if you have 45 countries in your GLM, then the linearized matrix should be 45 * 44 entries long. \n",
    "\n",
    "Note that indexing for GLM matrices in BEAST is also a little different. All entries to the top of the diagonal are sequentially filled in first, row by row. Then cell entries on the bottom of the matrix are filled in, row by row.\n",
    "\n",
    "XXXXXXX| usa |canada| mexico\n",
    "-------|-----|-------|-------\n",
    "usa    |XXXXX|  0    | 1\n",
    "canada |3    |XXXXXXX| 2\n",
    "mexico |4    |  5    | XXXXXX\n",
    "\n",
    "When linearized for the xml, the above predictor matrix takes the form of `[0, 1, 2, 3, 4, 5]`.\n",
    "\n",
    "If we have a dictionary, where the index is the key, and the value is a tuple, in form `(origin, destination)`, then the dictionary should look like this:\n",
    "\n",
    "`{0: ('usa', 'canada'), 1: ('usa', 'mexico'), 2: ('canada', 'mexico'), 3: ('canada', 'usa'), 4: ('mexico', 'usa'), 5: ('mexico', 'canada')}`\n",
    "\n",
    "Below, I'm formatting things a little differently. I'm actually going to use a nested dictionary structure where the key is the (origin,destination) tuple, and the value is a dictionary that includes index value, and  predictor values as pulled from a tsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify functions\n",
    "\n",
    "def logMatrix(matrix):\n",
    "    transformed_matrix = [math.log(value) for value in matrix]\n",
    "    return transformed_matrix\n",
    "\n",
    "def standardizeMatrix(matrix):\n",
    "    mean = np.mean(matrix)\n",
    "    stdev = np.std(matrix)\n",
    "    standardized_matrix = [(value - mean)/stdev for value in matrix]\n",
    "    return standardized_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# code to make the indexing dictionaries, adapted from Gytis Dudas' EBOV iPython notebook.\n",
    "# nothing crazy, just annoying math to deal with the bizarre GLM indexing.\n",
    "\n",
    "test_predictor_dict={}\n",
    "matrix_length=len(test_countries)\n",
    "for i in range(len(test_countries)):\n",
    "    for j in range(i+1,len(test_countries)): #make the second iteration 1 shorter than the first\n",
    "        index_1=int((matrix_length*(matrix_length-1)/2) - (matrix_length-i)*((matrix_length-i)-1)/2 + j - i - 1)\n",
    "        index_2=int((matrix_length*(matrix_length-1)) - (matrix_length-i)*((matrix_length-i)-1)/2 + j - i - 1)\n",
    "\n",
    "        test_predictor_dict[index_1] = {'country_pair':(test_countries[i],test_countries[j])}\n",
    "        test_predictor_dict[index_2] = {'country_pair':(test_countries[j],test_countries[i])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try importing test predictor set, and assigning great circle distances\n",
    "\n",
    "test_infile = '/Users/alliblk/Desktop/gitrepos/zika-usvi/data/predictors/test-predictors.tsv'\n",
    "with open(test_infile,'rU') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('origin'): # this line is the header of the tsv\n",
    "            predictor  = line.strip().split('\\t')[2] #predictor namein the tsv is what it will be called in dict\n",
    "        else:\n",
    "            country_tuple = (line.split('\\t')[0],line.split('\\t')[1]) # origin,destination tuple\n",
    "            for key in test_predictor_dict.keys():\n",
    "                if test_predictor_dict[key]['country_pair'] == country_tuple:\n",
    "                    test_predictor_dict[key][predictor] = float(line.strip().split('\\t')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'country_pair': ('united_states', 'canada'), 'great_circle_dist_km': 1077.10699075}, 1: {'country_pair': ('united_states', 'mexico'), 'great_circle_dist_km': 1922.06469663}, 2: {'country_pair': ('canada', 'mexico'), 'great_circle_dist_km': 2997.40071088}, 3: {'country_pair': ('canada', 'united_states'), 'great_circle_dist_km': 1077.10699075}, 4: {'country_pair': ('mexico', 'united_states'), 'great_circle_dist_km': 1922.06469663}, 5: {'country_pair': ('mexico', 'canada'), 'great_circle_dist_km': 2997.40071088}}\n"
     ]
    }
   ],
   "source": [
    "print test_predictor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1077.10699075, 1922.06469663, 2997.40071088, 1077.10699075, 1922.06469663, 2997.40071088]\n"
     ]
    }
   ],
   "source": [
    "# CHECK TO MAKE SURE EVERYTHING IS WORKING RIGHT!!! Should match up with indexing of markdown table above.\n",
    "\n",
    "test_linearized_predictor = []\n",
    "\n",
    "for i in range(len(test_predictor_dict)):\n",
    "    test_linearized_predictor.append(test_predictor_dict[i]['great_circle_dist_km'])\n",
    "\n",
    "print test_linearized_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.982034013680106, 7.561155250061531, 8.00550076237641, 6.982034013680106, 7.561155250061531, 8.00550076237641]\n",
      "7.51623000871\n",
      "0.41903440941\n"
     ]
    }
   ],
   "source": [
    "#try out log transforming matrix\n",
    "\n",
    "testLog_predictor = logMatrix(test_linearized_predictor)\n",
    "print testLog_predictor #yes, this looks right\n",
    "print np.mean(testLog_predictor)\n",
    "print np.std(testLog_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.2748260835608844, 0.10721134194857139, 1.1676147416123193, -1.2748260835608844, 0.10721134194857139, 1.1676147416123193]\n"
     ]
    }
   ],
   "source": [
    "std_matrix = standardizeMatrix(testLog_predictor)\n",
    "print std_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

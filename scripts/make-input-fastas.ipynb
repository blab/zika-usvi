{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README: Making input fasta files\n",
    "\n",
    "This script wrangles multiple sequence alignments and fasta files from `Nextstrain/fauna` to make fasta files of sequences that we want to include specifically in our analysis of Zika in the Americas. A variety of fasta files are outputted, including ones that can be read in to BEAST, and ones that can be read in to `Nextstrain/augur`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### import libraries ####\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "import datetime\n",
    "\n",
    "date = datetime.datetime.now().strftime (\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### infile paths #### \n",
    "zika_msa_stripped = \"/Users/alliblk/Desktop/gitrepos/augur-alliblk/zika/processed/zika_aligned_stripped.mfa\"\n",
    "fauna_file = \"/Users/alliblk/Desktop/gitrepos/fauna/data/zika.fasta\"\n",
    "\n",
    "#### outfile paths #### \n",
    "americas_file = '/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/american-zika-{}.fasta'.format(date)\n",
    "americas_frenchpol_file = '/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/american-frenchPolyn-zika-{}.fasta'.format(date)\n",
    "\n",
    "usvi_file = \"/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/usvi-{}.fasta\".format(date)\n",
    "usvi_primary_clade_file = '/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/usvi-primary-clade-{}.fasta'.format(date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### geographic exclusion criteria #### \n",
    "regions_to_exclude1 = ['southeast_asia', 'oceania', 'japan_korea', 'china','europe'] #french polynesia out\n",
    "regions_to_exclude2 = ['southeast_asia', 'japan_korea', 'china','europe'] #french polynesia in\n",
    "\n",
    "#reference info\n",
    "reference_strain_name = 'PF13/251013_18' #WHO reference strain for Zika, msa is stripped to this seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data: Make dictionaries that hold data in different structures\n",
    "\n",
    "* `strain_header_dict` maps strain name in augur form (key) to full fauna fauna header (value)\n",
    "* `fauna_dict` maps fauna taxon name (key) to the unaligned, unstripped sequence as it's stored in fauna (value)\n",
    "* `msa_dict` maps strain name in augur form (key) to the aligned and stripped-to-reference sequence (value). All sequences in this dictionary should therefore be 10769 nucleotides long, and are in frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dict that will allow matching of fauna header to MSA header\n",
    "with open(fauna_file,'rU') as file:\n",
    "    strain_header_dict={line.split('|')[0].replace('>',''):line.strip() for line in file if line.startswith('>')}\n",
    "\n",
    "# dict that will allow matching of fauna header to fauna sequnces (need this for making augur-formatted infiles)\n",
    "fauna_dict = SeqIO.to_dict(SeqIO.parse(fauna_file, 'fasta'))\n",
    "#print len(fauna_dict)\n",
    "\n",
    "# dict that has only strain name as key, but value is aligned, stripped to reference sequence\n",
    "zika_msa = AlignIO.read(open(zika_msa_stripped),'fasta')\n",
    "zika_msa_dict = {record.id:record.seq for record in zika_msa}\n",
    "\n",
    "for key in zika_msa_dict_pruned.keys():\n",
    "    assert len(zika_msa_dict_pruned[key]) == 10769"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment QC:\n",
    "\n",
    "I outline genome exclusion criteria in the README of the `data/fastas` directory. Genomes that should be excluded from my analysis are hardcoded in to Augur as `dropped_strains` in `zika.prepare.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "informative_bases = ['A','G','C','T']\n",
    "num_informative_bases = {}\n",
    "\n",
    "for key in fauna_dict.keys():\n",
    "    inform_base_count = 0\n",
    "    for base in fauna_dict[key].upper():\n",
    "        if base in informative_bases:\n",
    "            inform_base_count +=1\n",
    "        else:\n",
    "            continue\n",
    "    #n_counts[key.split('|')[0]] = n_count\n",
    "    num_informative_bases[key.split('|')[0]] = inform_base_count\n",
    "    #n_counts[key] = n_count\n",
    "#print n_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "['USA/2016/FL019', 'DOM/2016/MA_WGS16_009', 'DOM/2016/MA_WGS16_020', 'BRA/2016/FC_DQ12D1', 'USA/2016/FL035', 'HTI/2016/MA_WGS16_022', 'DOM/2016/BB_0428', 'HND/2016/HU_ME137', 'Bahia04', 'Bahia05', 'Bahia15', 'DOM/2016/MA_WGS16_031', 'JAM/2016/MA_WGS16_038', 'BRA/2016/FC_DQ68D1', 'Brazil/2016/ZBRY12']\n"
     ]
    }
   ],
   "source": [
    "low_information_genomes = {key:value for key,value in num_informative_bases.items() if value < 5000}\n",
    "print len(low_information_genomes)\n",
    "print low_information_genomes.keys()\n",
    "#these genomes will get added to the dropped_strains section of augur zika.prepare.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making fasta files formatted for input into Augur pipeline.\n",
    "\n",
    "Since Augur is a faster tool for building trees and doing ancestral state reconstruction than BEAST, I'm troubleshooting possible issues with the input alignment and looking for outliers (general dataset QC) via Augur builds. Augur input fasta files need to be formatted exactly the same was as the fauna output fasta file. So what I'm doing here is keeping header formatting the same as fauna, but subsampling down to exclude genomes from countries that I don't want to include, or samples that appear to be outliers etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prune dicts geographically\n",
    "# note that all of the samples that should be dropped except those specified in drop_augurPruned are \n",
    "# hardcoded into Augur as samples that should be dropped.\n",
    "# therefore they do not need to be dropped here in this script\n",
    "# I've entered them above mainly so I can keep stats on numbers of samples getting dropped and why\n",
    "geoPruned_fauna_dict_americasOnly = {key:value for key,value in fauna_dict.items() if key.split('|')[4] not in regions_to_exclude1 and key.split('|')[0] not in drop_augurPruned}\n",
    "geoPruned_fauna_dict_includeOceania = {key:value for key,value in fauna_dict.items() if key.split('|')[4] not in regions_to_exclude2 and key.split('|')[0] not in drop_augurPruned}\n",
    "\n",
    "#print out fauna-format files for input into augur\n",
    "\n",
    "# Americas only\n",
    "with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/augur-americas-only.fasta','w') as file:\n",
    "    for key in geoPruned_fauna_dict_americasOnly.keys():\n",
    "        file.write(str('>' + geoPruned_fauna_dict_americasOnly[key].description + '\\n' + geoPruned_fauna_dict_americasOnly[key].seq + '\\n'))\n",
    "        \n",
    "#Americas + french polynesia\n",
    "with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/augur-americas-andfp.fasta','w') as file:\n",
    "    for key in geoPruned_fauna_dict_includeOceania.keys():\n",
    "        file.write(str('>' + geoPruned_fauna_dict_includeOceania[key].description + '\\n' + geoPruned_fauna_dict_includeOceania[key].seq + '\\n'))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the augur processed multiple sequence alignment with the fauna-output fasta\n",
    "\n",
    "Here I want to combine attributes of both the `Nextstrain/augur` processed Zika MSA with the fasta output from `Nextstrain/fauna`. The Fauna download has the strain information in the desired fasta format, with all necessary metadata (sampling date, geography) in the header. The processed multiple sequence alignment however has been aligned with mafft and stripped to the WHO ZIKV reference genome, and therefore represents the sequence alignment that we want.\n",
    "\n",
    "The header from the MSA contains the strain name of the sample, which is also in the fauna header. Therefore I will use key matching to make a new fasta file that combines the header from the fauna file with the sequences from the augur msa. The fauna header will be trimmed down when writing out the fastas to remove superfluous information in the header and to ensure that the headers can be read in to FigTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n",
      "299\n",
      "26\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "output_dict = {}\n",
    "for key in zika_msa_dict_pruned.keys():\n",
    "    header = strain_header_dict[key]\n",
    "    seq = zika_msa_dict_pruned[key]\n",
    "    output_dict[header] = seq\n",
    "\n",
    "americas_count = 0\n",
    "oceania_count = 0\n",
    "non_americas_non_oceania_count = 0 \n",
    "\n",
    "for key in output_dict.keys():\n",
    "    if key.split('|')[4] not in regions_to_exclude1:\n",
    "        americas_count += 1\n",
    "    elif key.split('|')[4] == 'oceania':\n",
    "        oceania_count += 1\n",
    "    elif key.split('|')[4] in regions_to_exclude1:\n",
    "        non_americas_non_oceania_count += 1\n",
    "\n",
    "print len(output_dict.keys())\n",
    "print americas_count\n",
    "print oceania_count\n",
    "print non_americas_non_oceania_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print out Americas only multiple sequence alignment\n",
    "with open(americas_file,'w') as out_file:\n",
    "    for key in output_dict.keys():\n",
    "        if key.split('|')[4] in regions_to_exclude1:\n",
    "            continue\n",
    "        else:\n",
    "            split_name = key.split('|')\n",
    "            header = split_name[0] +'|'+ split_name[3] + '|'+ split_name[4] + '|'+ split_name[5]\n",
    "            out_file.write(str(header + '\\n' + output_dict[key] + '\\n'))\n",
    "\n",
    "# Uncomment to print out alignment that still contains french polynesian sequences\n",
    "#print out Americas and french polynesia multiple sequence alignment\n",
    "'''\n",
    "with open(americas_frenchpol_file,'w') as out_file:\n",
    "    for key in output_dict.keys():\n",
    "        if key.split('|')[4] in regions_to_exclude2:\n",
    "            continue\n",
    "        else:\n",
    "            split_name = key.split('|')\n",
    "            header = split_name[0] +'|'+ split_name[3] + '|'+ split_name[4] + '|'+ split_name[5] \n",
    "            out_file.write(str(header + '\\n' + output_dict[key] + '\\n'))\n",
    "'''\n",
    "#print out USVI only multiple sequence alignment\n",
    "with open(usvi_file,'w') as out_file:\n",
    "    for key in output_dict.keys():\n",
    "        if key.split('|')[5] == 'usvi':\n",
    "            split_name = key.split('|')\n",
    "            header = split_name[0] +'|'+ split_name[3] + '|'+ split_name[4] + '|'+ split_name[5]\n",
    "            out_file.write(str(header + '\\n' + output_dict[key] + '\\n'))\n",
    "        else:\n",
    "            continue\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

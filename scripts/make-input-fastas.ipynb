{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README: Making input fasta files\n",
    "\n",
    "This script wrangles multiple sequence alignments and fasta files from `Nextstrain/fauna` to make fasta files of sequences that we want to include specifically in our analysis of Zika in the Americas. A variety of fasta files are outputted, including ones that can be read in to BEAST, and ones that can be read in to `Nextstrain/augur`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### import libraries ####\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "import datetime\n",
    "import pandas as pd\n",
    "date = datetime.datetime.now().strftime (\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### infile paths #### \n",
    "zika_msa_stripped = \"/Users/alliblk/Desktop/gitrepos/augur-alliblk/zika/processed/zika_aligned_stripped.mfa\"\n",
    "fauna_file = \"/Users/alliblk/Desktop/gitrepos/fauna/data/zika.fasta\"\n",
    "\n",
    "#### outfile paths #### \n",
    "americas_file = '/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/american-zika-{}.fasta'.format(date)\n",
    "americas_frenchpol_file = '/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/american-frenchPolyn-zika-{}.fasta'.format(date)\n",
    "\n",
    "usvi_file = \"/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/usvi-{}.fasta\".format(date)\n",
    "usvi_primary_clade_file = '/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/usvi-primary-clade-{}.fasta'.format(date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load in all available sequences in from Fauna. This should be all Zika genomes that have been made publicly available on GenBank, ViPR, and GitHub. Note that this does NOT mean that all of the genomes have been published on.\n",
    "\n",
    "Note that you will need to clone the `nextstrain/fauna` git repo and run fauna to have this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542 sequences available from Fauna\n"
     ]
    }
   ],
   "source": [
    "fauna_file = \"/Users/alliblk/Desktop/gitrepos/fauna/data/zika.fasta\"\n",
    "fauna_dict = SeqIO.to_dict(SeqIO.parse(fauna_file, 'fasta'))\n",
    "print '{} sequences available from Fauna'.format(len(fauna_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Make a subset of the fauna sequences that only includes the geographic regions of interest. Here, I want only Zika sequences from the Americas. I need an outgroup sequence to properly root the tree however, so I'm also going to include a single genome from French Polynesia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 sequences meet the geographic and outgroup criteria\n"
     ]
    }
   ],
   "source": [
    "regions_to_exclude = ['southeast_asia', 'oceania', 'japan_korea', 'china','europe']\n",
    "reference_strain_name = 'PF13/251013_18' # outgroup. This is the WHO reference strain for Zika, msa will also be stripped to this seq.\n",
    "\n",
    "\n",
    "geoPruned_fauna_dict = {fauna_dict[key].description:fauna_dict[key].seq for key in fauna_dict.keys() if key.split('|')[4] not in regions_to_exclude or key.split('|')[0] == reference_strain_name}\n",
    "print '{} sequences meet the geographic and outgroup criteria'.format(len(geoPruned_fauna_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Filter sequences so that we only include sequences that we are allowed to publish on. These include any sequences that have been previously released during publication, or any sequences for which the authors have given us permission to use them in our analysis.\n",
    "\n",
    "This information has been collated in a table that I'm going to import in here. Note that the table is NOT exhaustive for all genomes available from Fauna. Rather, it only includes sequences from the Americas. Sequence accessions have been manually checked and matched with publications if they are published on (with pubmed ID information). If not published on, sequences have a flag that denotes whether author permission was received or not.\n",
    "\n",
    "I have an indicator in this table as well that is labeled `premliminarily_include`. If a record says `no` in this column, it is because it needed permissions to be requested, but would likely not add more to the analysis, and therefore was deemed not necessary to pursue permissions on.\n",
    "\n",
    "Below I have lists of all the publications as they're listed in the Fauna headers, which represent the title given in GenBank but _not necessarily the title of the actual published manuscript_. They are divided into publications that are published, ones that are not published, and ones that are in fact published but the actual manuscript name is different than the GenBank publication name, and therefore they appear to be unpublished in GenBank.\n",
    "\n",
    "---------------\n",
    "\n",
    "`published_submissions` = ['First Complete Genome Sequence of Zika Virus (Flaviviridae, Flavivirus) from an Autochthonous Transmission in Brazil',\n",
    "'Genetic characterization of the Zika virus epidemic in the US Virgin Islands',\n",
    "'Isolation of Infective Zika Virus from Urine and Saliva of Patients in Brazil',\n",
    "'Full-length infectious cDNA clone of Zika virus from 2015 epidemic in Brazil: development and characterization of recombinant viruses in cell lines from human placenta, testis, and brain',\n",
    "'Zika virus complete genome from Salvador, Bahia, Brazil',\n",
    "'Complete Genome Sequences of Three Historically Important, Spatiotemporally Distinct, and Genetically Divergent Strains of Zika Virus: MR-766, P6-740, and PRVABC-59',\n",
    "'Isolation of infectious Zika virus from saliva and prolonged viral RNA shedding in a traveller returning from the Dominican Republic to Italy, January 2016',\n",
    "'Fatal Zika Virus Infection with Secondary Nonsexual Transmission',\n",
    "'Quasispecies composition and evolution of a typical Zika virus clinical isolate from Suriname',\n",
    "'First Complete Genome Sequences of Zika Virus Isolated from Febrile Patient Sera in Ecuador',\n",
    "'Epidemic establishment and cryptic transmission of Zika virus in Brazil and the Americas',\n",
    "'Genomic epidemiology reveals multiple introductions of Zika virus into the United States',\n",
    "'Coinfection With Zika and Dengue-2 Viruses in a Traveler Returning From Haiti, 2016: Clinical Presentation and Genetic Analysis',\n",
    "'Multiplex PCR method for MinION and Illumina sequencing of Zika and other virus genomes directly from clinical samples',\n",
    "'Large returning population of oversea Chinese of Guangdong province combined with tourists increase the risks of ZIKV transmission in Guangdong, China',\n",
    "'Zika Virus Targets Different Primary Human Placental Cells, Suggesting Two Routes for Vertical Transmission',\n",
    "'Establishment and cryptic transmission of Zika virus in Brazil and the Americas',\n",
    "'Zika Virus Outbreak in Haiti in 2014: Molecular and Clinical Data',\n",
    "'Prolonged Detection of Zika Virus in Vaginal Secretions and Whole Blood',\n",
    "'Complete Genome Sequences of Identical Zika virus Isolates in a Nursing Mother and Her Infant',\n",
    "'?',\n",
    "'Zika virus in the Americas: early epidemiological and genetic findings',\n",
    "'Full Genome Sequence and sfRNA Interferon Antagonist Activity of Zika Virus from Recife, Brazil',\n",
    "'Distinct Zika Virus Lineage in Salvador, Bahia, Brazil',\n",
    "'Genome sequence of a candidate World Health Organization reference strain for Zika virus for nucleic acid testing',\n",
    "'Zika virus evolution and spread in the Americas',\n",
    "'Zika virus genome from the Americas',\n",
    "'Complete coding sequence of Zika virus from Martinique outbreak in 2015',\n",
    "'Zika Virus Associated with Microcephaly',\n",
    "'Characterization of a Zika Virus Isolate from Colombia',\n",
    "'Detection and sequencing of Zika virus from amniotic fluid of fetuses with microcephaly in Brazil: a case study',\n",
    "'Phylogeny of Zika Virus in Western Hemisphere, 2015',\n",
    "'Complete genomic sequence of Zika virus isolated from a clinical semen sample',\n",
    "'Infection dynamics in a traveller with persistent shedding of Zika virus RNA in semen for six months after returning from Haiti to Italy, January 2016',                        \n",
    "                  ]\n",
    "\n",
    "`published_submissions_with_incorrect_publication_name` = [ 'Complete Zika Virus Genome Sequences from a Serum Sample and after Isolation in Vero Cells',\n",
    "'Full coding sequence of the Zika Virus isolate HS-2015-BA-01',\n",
    "'Large returning population of oversea Chinese of Guangdong province combined with tourists increase the risks of ZIKV transmission in Guangdong, China',\n",
    "'The isolation and characterization of Zika virus imported into Guangdong, China',\n",
    "'Full genomic characterization of a Zika virus isolate from Colombia',\n",
    "'Molecular characterization of Zika virus in Mexico',\n",
    "'Repurposed drug candidates to treat ZIKV infection in pregnancy',\n",
    "'Full-genome amplification and sequencing of Zika viruses using a targeted amplification approach',\n",
    "'Zika virus infection with prolonged maternal viremia and fetal brain abnormalities',\n",
    "'Complete genome of Zika virus GZ01 isolate from China',\n",
    "'Complete genomic sequence of Zika virus isolated from a traveler to Colombia in 2016',\n",
    "                                                       \n",
    "                                                         \n",
    "]\n",
    "\n",
    "`unpublished_submissions` = [\n",
    "'Imported cases of Zika virus disease in Russia in 2016-2017',\n",
    "'Complete Genome of a Zika Virus Isolate, Amazonas, Brazil, 2016',\n",
    "'Imported cases of Zika virus disease in Russia in 2016-2017',\n",
    "'Zika viral sequence identified in Fortaleza, Brazil',\n",
    "'Comparative analysis between the genomes of intra-host and cell cultured Zika virus obtained from a Mexican symptomatic patient'\n",
    "'Zika virus from breast milk',\n",
    "'Genome sequences of Zika viruses isolated in Nicaragua',              \n",
    "'Emergence of Zika virus in Brazil: Detection of Asian genotype',\n",
    "'Brazilian Zika virus genome sequence',\n",
    "'Zika viruses in Haiti during an outbreak of Chikungunya Fever in mid 2014', #white et al sequences\n",
    "'Zika virus sequence from Cuba traveler diagnosed in the United States (Miami, FL)', #nate\n",
    "'Zika virus genomes from human cases in Florida, USA',\n",
    "'Isolation of infectious Zika virus from sera in a traveller returning from Brazil to Italy',\n",
    "'Zika virus infection in pregnant mice',\n",
    "'Zika virus polyprotein sequence isolated from a fetus-brain of Cuba pregnant traveler diagnosed in Spain (Madrid)',\n",
    "'Genome sequences of four Zika virus isolates from Brazil',\n",
    "'Direct Submission'\n",
    "                          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain_name</th>\n",
       "      <th>accession_number</th>\n",
       "      <th>lead_author</th>\n",
       "      <th>permission_type</th>\n",
       "      <th>publication_pubmed_id</th>\n",
       "      <th>permission_to_use</th>\n",
       "      <th>preliminarily_include</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHE_Guadeloupe</td>\n",
       "      <td>KX673530</td>\n",
       "      <td>Atkinson</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>27738033.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEX_I_7</td>\n",
       "      <td>KX247632</td>\n",
       "      <td>Barrows</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>27476412.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dominican_Republic/2016/PD1</td>\n",
       "      <td>KU853012</td>\n",
       "      <td>Barzon</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>26987769.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haiti/2016/PD</td>\n",
       "      <td>KX269878</td>\n",
       "      <td>Barzon</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>27542178.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USVI/1/2016</td>\n",
       "      <td>VI1</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USVI/11/2016</td>\n",
       "      <td>VI11</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>USVI/12/2016</td>\n",
       "      <td>VI12</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>USVI/13/2016</td>\n",
       "      <td>VI13</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>USVI/19/2016</td>\n",
       "      <td>VI19</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>USVI/2/2016</td>\n",
       "      <td>VI2</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USVI/20/2016</td>\n",
       "      <td>VI20</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>USVI/21/2016</td>\n",
       "      <td>VI21</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>USVI/22/2016</td>\n",
       "      <td>VI22</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>USVI/23/2016</td>\n",
       "      <td>VI23</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>USVI/24/2016</td>\n",
       "      <td>VI24</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>USVI/25/2016</td>\n",
       "      <td>VI25</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>USVI/27/2016</td>\n",
       "      <td>VI27</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>USVI/28/2016</td>\n",
       "      <td>VI28</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>USVI/3/2016</td>\n",
       "      <td>VI3</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>USVI/30/2016</td>\n",
       "      <td>VI30</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>USVI/32/2016</td>\n",
       "      <td>VI32</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>USVI/34/2016</td>\n",
       "      <td>VI34</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>USIV/35/2016</td>\n",
       "      <td>VI35</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>USVI/36/2016</td>\n",
       "      <td>VI36</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>USVI/37/2016</td>\n",
       "      <td>VI37</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>USVI/38/2016</td>\n",
       "      <td>VI38</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>USVI/39/2016</td>\n",
       "      <td>VI39</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>USVI/4/2016</td>\n",
       "      <td>VI4</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>USVI/40/2016</td>\n",
       "      <td>VI40</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>USVI/41/2016</td>\n",
       "      <td>VI41</td>\n",
       "      <td>Black</td>\n",
       "      <td>published_here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>PAN/CDC_259359_V1_V3/2015</td>\n",
       "      <td>KX156774</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>PAN/CDC_259249_V1_V3/2015</td>\n",
       "      <td>KX156775</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>PAN/CDC_259364_V1-V2/2015</td>\n",
       "      <td>KX156776</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>PAN/BEI_259634_V4/2016</td>\n",
       "      <td>KX198135</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Aedessp/MEX/MEX_2_81/2016</td>\n",
       "      <td>KX446950</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Aedessp/MEX/MEX_I_7/2016</td>\n",
       "      <td>KX446951</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>HND/R103451/2015</td>\n",
       "      <td>KX694534</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Aedes_aegypti/MEX/MEX_I_44/2016</td>\n",
       "      <td>KY648934</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>NIC/7252_12A1/2016</td>\n",
       "      <td>KY765317</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>NIC/4886_12A1/2016</td>\n",
       "      <td>KY765318</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>NIC/6406_13A1/2016</td>\n",
       "      <td>KY765320</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>NIC/6188_13A1/2016</td>\n",
       "      <td>KY765323</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>NIC/8610_13A1/2016</td>\n",
       "      <td>KY765324</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>HND/R103451/2015</td>\n",
       "      <td>KX694534</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>NIC/4886_12A1_SP/2016</td>\n",
       "      <td>KY765321</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>NIC/6188_13A1/2016</td>\n",
       "      <td>KY765326</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>NIC/5005_13A1/2016</td>\n",
       "      <td>KY765327</td>\n",
       "      <td>Shabman</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>NL00013</td>\n",
       "      <td>KU937936</td>\n",
       "      <td>Stalin Raj V</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Z16019</td>\n",
       "      <td>KU955590</td>\n",
       "      <td>Sun</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>28712937.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>USA/UT_1/2016</td>\n",
       "      <td>KX827268</td>\n",
       "      <td>Swaminathan</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>27681699.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Nica2_16</td>\n",
       "      <td>KX421194</td>\n",
       "      <td>Tabata</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>27443522.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Nica1_16</td>\n",
       "      <td>KX421195</td>\n",
       "      <td>Tabata</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>27443522.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>PF13/251013_18</td>\n",
       "      <td>KX369547</td>\n",
       "      <td>Troesemeier</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>27587826.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Paraiba_01</td>\n",
       "      <td>KX280026</td>\n",
       "      <td>Tsetsarkin</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>27555311.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>SL1602</td>\n",
       "      <td>KY348640</td>\n",
       "      <td>Van Boheemen</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>28539654.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>HS_2015_BA_01</td>\n",
       "      <td>KX520666</td>\n",
       "      <td>Xavier-neto</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>28231241.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>PRVABC59</td>\n",
       "      <td>KX377337</td>\n",
       "      <td>Yun</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>27540058.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>GZ01</td>\n",
       "      <td>KU820898</td>\n",
       "      <td>Zhang</td>\n",
       "      <td>previously_published</td>\n",
       "      <td>27184420.0</td>\n",
       "      <td>not_necessary</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ZBRC13</td>\n",
       "      <td>ZBRC13</td>\n",
       "      <td>ZiBRA</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>ZBRC15</td>\n",
       "      <td>ZBRC15</td>\n",
       "      <td>ZiBRA</td>\n",
       "      <td>unpublished</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permission_not_received</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         strain_name accession_number   lead_author  \\\n",
       "0                     PHE_Guadeloupe         KX673530      Atkinson   \n",
       "1                            MEX_I_7         KX247632       Barrows   \n",
       "2        Dominican_Republic/2016/PD1         KU853012        Barzon   \n",
       "3                      Haiti/2016/PD         KX269878        Barzon   \n",
       "4                        USVI/1/2016              VI1         Black   \n",
       "5                       USVI/11/2016             VI11         Black   \n",
       "6                       USVI/12/2016             VI12         Black   \n",
       "7                       USVI/13/2016             VI13         Black   \n",
       "8                       USVI/19/2016             VI19         Black   \n",
       "9                        USVI/2/2016              VI2         Black   \n",
       "10                      USVI/20/2016             VI20         Black   \n",
       "11                      USVI/21/2016             VI21         Black   \n",
       "12                      USVI/22/2016             VI22         Black   \n",
       "13                      USVI/23/2016             VI23         Black   \n",
       "14                      USVI/24/2016             VI24         Black   \n",
       "15                      USVI/25/2016             VI25         Black   \n",
       "16                      USVI/27/2016             VI27         Black   \n",
       "17                      USVI/28/2016             VI28         Black   \n",
       "18                       USVI/3/2016              VI3         Black   \n",
       "19                      USVI/30/2016             VI30         Black   \n",
       "20                      USVI/32/2016             VI32         Black   \n",
       "21                      USVI/34/2016             VI34         Black   \n",
       "22                      USIV/35/2016             VI35         Black   \n",
       "23                      USVI/36/2016             VI36         Black   \n",
       "24                      USVI/37/2016             VI37         Black   \n",
       "25                      USVI/38/2016             VI38         Black   \n",
       "26                      USVI/39/2016             VI39         Black   \n",
       "27                       USVI/4/2016              VI4         Black   \n",
       "28                      USVI/40/2016             VI40         Black   \n",
       "29                      USVI/41/2016             VI41         Black   \n",
       "..                               ...              ...           ...   \n",
       "265        PAN/CDC_259359_V1_V3/2015         KX156774       Shabman   \n",
       "266        PAN/CDC_259249_V1_V3/2015         KX156775       Shabman   \n",
       "267        PAN/CDC_259364_V1-V2/2015         KX156776       Shabman   \n",
       "268           PAN/BEI_259634_V4/2016         KX198135       Shabman   \n",
       "269        Aedessp/MEX/MEX_2_81/2016         KX446950       Shabman   \n",
       "270         Aedessp/MEX/MEX_I_7/2016         KX446951       Shabman   \n",
       "271                 HND/R103451/2015         KX694534       Shabman   \n",
       "272  Aedes_aegypti/MEX/MEX_I_44/2016         KY648934       Shabman   \n",
       "273               NIC/7252_12A1/2016         KY765317       Shabman   \n",
       "274               NIC/4886_12A1/2016         KY765318       Shabman   \n",
       "275               NIC/6406_13A1/2016         KY765320       Shabman   \n",
       "276               NIC/6188_13A1/2016         KY765323       Shabman   \n",
       "277               NIC/8610_13A1/2016         KY765324       Shabman   \n",
       "278                 HND/R103451/2015         KX694534       Shabman   \n",
       "279            NIC/4886_12A1_SP/2016         KY765321       Shabman   \n",
       "280               NIC/6188_13A1/2016         KY765326       Shabman   \n",
       "281               NIC/5005_13A1/2016         KY765327       Shabman   \n",
       "282                          NL00013         KU937936  Stalin Raj V   \n",
       "283                           Z16019         KU955590           Sun   \n",
       "284                    USA/UT_1/2016         KX827268   Swaminathan   \n",
       "285                         Nica2_16         KX421194        Tabata   \n",
       "286                         Nica1_16         KX421195        Tabata   \n",
       "287                   PF13/251013_18         KX369547   Troesemeier   \n",
       "288                       Paraiba_01         KX280026    Tsetsarkin   \n",
       "289                           SL1602         KY348640  Van Boheemen   \n",
       "290                    HS_2015_BA_01         KX520666   Xavier-neto   \n",
       "291                         PRVABC59         KX377337           Yun   \n",
       "292                             GZ01         KU820898         Zhang   \n",
       "293                           ZBRC13           ZBRC13         ZiBRA   \n",
       "294                           ZBRC15           ZBRC15         ZiBRA   \n",
       "\n",
       "          permission_type  publication_pubmed_id        permission_to_use  \\\n",
       "0    previously_published             27738033.0            not_necessary   \n",
       "1    previously_published             27476412.0            not_necessary   \n",
       "2    previously_published             26987769.0            not_necessary   \n",
       "3    previously_published             27542178.0            not_necessary   \n",
       "4          published_here                    NaN            not_necessary   \n",
       "5          published_here                    NaN            not_necessary   \n",
       "6          published_here                    NaN            not_necessary   \n",
       "7          published_here                    NaN            not_necessary   \n",
       "8          published_here                    NaN            not_necessary   \n",
       "9          published_here                    NaN            not_necessary   \n",
       "10         published_here                    NaN            not_necessary   \n",
       "11         published_here                    NaN            not_necessary   \n",
       "12         published_here                    NaN            not_necessary   \n",
       "13         published_here                    NaN            not_necessary   \n",
       "14         published_here                    NaN            not_necessary   \n",
       "15         published_here                    NaN            not_necessary   \n",
       "16         published_here                    NaN            not_necessary   \n",
       "17         published_here                    NaN            not_necessary   \n",
       "18         published_here                    NaN            not_necessary   \n",
       "19         published_here                    NaN            not_necessary   \n",
       "20         published_here                    NaN            not_necessary   \n",
       "21         published_here                    NaN            not_necessary   \n",
       "22         published_here                    NaN            not_necessary   \n",
       "23         published_here                    NaN            not_necessary   \n",
       "24         published_here                    NaN            not_necessary   \n",
       "25         published_here                    NaN            not_necessary   \n",
       "26         published_here                    NaN            not_necessary   \n",
       "27         published_here                    NaN            not_necessary   \n",
       "28         published_here                    NaN            not_necessary   \n",
       "29         published_here                    NaN            not_necessary   \n",
       "..                    ...                    ...                      ...   \n",
       "265           unpublished                    NaN  permission_not_received   \n",
       "266           unpublished                    NaN  permission_not_received   \n",
       "267           unpublished                    NaN  permission_not_received   \n",
       "268           unpublished                    NaN  permission_not_received   \n",
       "269           unpublished                    NaN  permission_not_received   \n",
       "270           unpublished                    NaN  permission_not_received   \n",
       "271           unpublished                    NaN  permission_not_received   \n",
       "272           unpublished                    NaN  permission_not_received   \n",
       "273           unpublished                    NaN  permission_not_received   \n",
       "274           unpublished                    NaN  permission_not_received   \n",
       "275           unpublished                    NaN  permission_not_received   \n",
       "276           unpublished                    NaN  permission_not_received   \n",
       "277           unpublished                    NaN  permission_not_received   \n",
       "278           unpublished                    NaN  permission_not_received   \n",
       "279           unpublished                    NaN  permission_not_received   \n",
       "280           unpublished                    NaN  permission_not_received   \n",
       "281           unpublished                    NaN  permission_not_received   \n",
       "282           unpublished                    NaN  permission_not_received   \n",
       "283  previously_published             28712937.0            not_necessary   \n",
       "284  previously_published             27681699.0            not_necessary   \n",
       "285  previously_published             27443522.0            not_necessary   \n",
       "286  previously_published             27443522.0            not_necessary   \n",
       "287  previously_published             27587826.0            not_necessary   \n",
       "288  previously_published             27555311.0            not_necessary   \n",
       "289  previously_published             28539654.0            not_necessary   \n",
       "290  previously_published             28231241.0            not_necessary   \n",
       "291  previously_published             27540058.0            not_necessary   \n",
       "292  previously_published             27184420.0            not_necessary   \n",
       "293           unpublished                    NaN  permission_not_received   \n",
       "294           unpublished                    NaN  permission_not_received   \n",
       "\n",
       "    preliminarily_include  \n",
       "0                     yes  \n",
       "1                     yes  \n",
       "2                     yes  \n",
       "3                     yes  \n",
       "4                     yes  \n",
       "5                     yes  \n",
       "6                     yes  \n",
       "7                     yes  \n",
       "8                     yes  \n",
       "9                     yes  \n",
       "10                    yes  \n",
       "11                    yes  \n",
       "12                    yes  \n",
       "13                    yes  \n",
       "14                    yes  \n",
       "15                    yes  \n",
       "16                    yes  \n",
       "17                    yes  \n",
       "18                    yes  \n",
       "19                    yes  \n",
       "20                    yes  \n",
       "21                    yes  \n",
       "22                    yes  \n",
       "23                    yes  \n",
       "24                    yes  \n",
       "25                    yes  \n",
       "26                    yes  \n",
       "27                    yes  \n",
       "28                    yes  \n",
       "29                    yes  \n",
       "..                    ...  \n",
       "265                   yes  \n",
       "266                   yes  \n",
       "267                   yes  \n",
       "268                   yes  \n",
       "269                   yes  \n",
       "270                   yes  \n",
       "271                   yes  \n",
       "272                   yes  \n",
       "273                   yes  \n",
       "274                   yes  \n",
       "275                   yes  \n",
       "276                   yes  \n",
       "277                   yes  \n",
       "278                   yes  \n",
       "279                   yes  \n",
       "280                   yes  \n",
       "281                   yes  \n",
       "282                   yes  \n",
       "283                   yes  \n",
       "284                   yes  \n",
       "285                   yes  \n",
       "286                   yes  \n",
       "287                   yes  \n",
       "288                   yes  \n",
       "289                   yes  \n",
       "290                   yes  \n",
       "291                   yes  \n",
       "292                   yes  \n",
       "293                    no  \n",
       "294                    no  \n",
       "\n",
       "[295 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permission_info = pd.read_excel('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/sequences_and_permissions.xlsx')\n",
    "permission_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n"
     ]
    }
   ],
   "source": [
    "strains_with_permission = []\n",
    "\n",
    "for i in range(len(permission_info)):\n",
    "    record = permission_info.iloc[i]\n",
    "    if record['permission_to_use'] != 'permission_not_received' and record['preliminarily_include'] == 'yes':\n",
    "        strains_with_permission.append(record['strain_name'])\n",
    "\n",
    "print len(strains_with_permission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n"
     ]
    }
   ],
   "source": [
    "useable_genomes_dict_faunaHeader = {}\n",
    "useable_genomes_dict_augurHeader = {}\n",
    "#making a dict for each kind of header here because it's really nice to have both when troubleshooting.\n",
    "for strain in strains_with_permission:\n",
    "    for key in geoPruned_fauna_dict.keys():\n",
    "        if key.startswith(strain):\n",
    "            useable_genomes_dict_faunaHeader[key] = geoPruned_fauna_dict[key]\n",
    "            useable_genomes_dict_augurHeader[key.split('|')[0]] = geoPruned_fauna_dict[key]\n",
    "\n",
    "print len(useable_genomes_dict_faunaHeader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Now that we have our set of genomes that we can use, it's time to do some preliminary alignment quality control. I outline genome exclusion criteria in the README of the `data/fastas` directory. Genomes that should be excluded from my analysis are hardcoded in to Augur as `dropped_strains` in `zika.prepare.py`. Most of the process of determining outlier clades is done iteratively based on Augur builds of the tree, however filtering out strains with less that 5000 informative sites is something that I do in this notebook (below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write out files that Augur will take in\n",
    "with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/augur-publishedAmericanSeqs-and-ref.fasta','w') as file:\n",
    "    for key in useable_genomes_dict_faunaHeader.keys():\n",
    "        file.write(str('>' + key + '\\n' + useable_genomes_dict_faunaHeader[key] + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "['USA/2016/FL019', 'DOM/2016/MA_WGS16_009', 'DOM/2016/MA_WGS16_020', 'BRA/2016/FC_DQ12D1', 'USA/2016/FL035', 'HTI/2016/MA_WGS16_022', 'DOM/2016/BB_0428', 'HND/2016/HU_ME137', 'Bahia04', 'Bahia05', 'Bahia15', 'DOM/2016/MA_WGS16_031', 'JAM/2016/MA_WGS16_038', 'BRA/2016/FC_DQ68D1', 'Brazil/2016/ZBRY12']\n"
     ]
    }
   ],
   "source": [
    "informative_bases = ['A','G','C','T']\n",
    "num_informative_bases = {}\n",
    "\n",
    "for key in fauna_dict.keys():\n",
    "    inform_base_count = 0\n",
    "    for base in fauna_dict[key].upper():\n",
    "        if base in informative_bases:\n",
    "            inform_base_count +=1\n",
    "        else:\n",
    "            continue\n",
    "    num_informative_bases[key.split('|')[0]] = inform_base_count\n",
    "\n",
    "low_information_genomes = {key:value for key,value in num_informative_bases.items() if value < 5000}\n",
    "print len(low_information_genomes)\n",
    "print low_information_genomes.keys() #these genomes will get added to the dropped_strains section of augur zika.prepare.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... Interlude here to do all the exploration in Augur ...\n",
    "\n",
    "Done :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Now that I have the alignment that I want to use, including a good sequence set that is aligned and stripped to reference, I want to make fasta files that I can read in to BEAST that make use of sequences from the multiple sequence aligment, but have fully informative headers (which I'll need to grab from Fauna). \n",
    "\n",
    "Basically, I'll need to use these three dictionaries to do this:\n",
    "\n",
    "* `strain_header_dict` maps strain name in augur form (key) to full fauna fauna header (value).\n",
    "* `fauna_dict` (which I made earlier in the script) maps fauna taxon name (key) to the unaligned, unstripped sequence as it's stored in fauna (value).\n",
    "* `msa_dict` maps strain name in augur form (key) to the aligned and stripped-to-reference sequence (value). All sequences in this dictionary should therefore be 10769 nucleotides long, and are in frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make strain_header_dict\n",
    "with open(fauna_file,'rU') as file:\n",
    "    strain_header_dict={line.split('|')[0].replace('>',''):line.strip() for line in file if line.startswith('>')}\n",
    "\n",
    "#make msa dict\n",
    "zika_msa = AlignIO.read(open(zika_msa_stripped),'fasta')\n",
    "zika_msa_dict = {record.id:record.seq for record in zika_msa}\n",
    "\n",
    "#make sure the alignment is the same length as the reference sequence that it should be mapped to.\n",
    "for key in zika_msa_dict.keys():\n",
    "    assert len(zika_msa_dict[key]) == 10769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "output_dict = {}\n",
    "for key in zika_msa_dict.keys():\n",
    "    header = strain_header_dict[key] #grab full fauna header from strain_header_dict\n",
    "    seq = zika_msa_dict[key] #get sequence from msa\n",
    "    output_dict[header] = seq\n",
    "\n",
    "print len(output_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write output dict to fasta\n",
    "with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/beast-americasZika-outgrouped.fasta','w') as out_file:\n",
    "    for key in output_dict.keys():\n",
    "            split_name = key.split('|')\n",
    "            header = split_name[0] +'|'+ split_name[3] + '|'+ split_name[4] + '|'+ split_name[5]\n",
    "            out_file.write(str(header + '\\n' + output_dict[key] + '\\n'))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside:\n",
    "Below is the code I used to initally start looking at accessions and publications to determine which genomes were freely available to include in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# want dict where {publication: [accession, accession]}\n",
    "publication_accessions_dict = {}\n",
    "for pub in list_of_pubs:\n",
    "    accessions = []\n",
    "    for key in fauna_dict.keys():\n",
    "        taxa = fauna_dict[key].description\n",
    "        if taxa.split('|')[12] == pub:\n",
    "            accessions.append(taxa.split('|')[2])\n",
    "    publication_accessions_dict[pub] = accessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pub_seq_count = 0\n",
    "for pub in published_submissions:\n",
    "    print len(publication_accessions_dict[pub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "published_seqs = defaultdict(int)\n",
    "\n",
    "list_of_pubs = [strain_header_dict[key].split('|')[12] for key in zika_msa_dict.keys()]\n",
    "\n",
    "for pub in list_of_pubs:\n",
    "    published_seqs[pub] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "published_submissions= ['First Complete Genome Sequence of Zika Virus (Flaviviridae, Flavivirus) from an Autochthonous Transmission in Brazil',\n",
    "'Genetic characterization of the Zika virus epidemic in the US Virgin Islands',\n",
    "'Isolation of Infective Zika Virus from Urine and Saliva of Patients in Brazil',\n",
    "'Full-length infectious cDNA clone of Zika virus from 2015 epidemic in Brazil: development and characterization of recombinant viruses in cell lines from human placenta, testis, and brain',\n",
    "'Zika virus complete genome from Salvador, Bahia, Brazil',\n",
    "'Complete Genome Sequences of Three Historically Important, Spatiotemporally Distinct, and Genetically Divergent Strains of Zika Virus: MR-766, P6-740, and PRVABC-59',\n",
    "'Isolation of infectious Zika virus from saliva and prolonged viral RNA shedding in a traveller returning from the Dominican Republic to Italy, January 2016',\n",
    "'Fatal Zika Virus Infection with Secondary Nonsexual Transmission',\n",
    "'Quasispecies composition and evolution of a typical Zika virus clinical isolate from Suriname',\n",
    "'First Complete Genome Sequences of Zika Virus Isolated from Febrile Patient Sera in Ecuador',\n",
    "'Epidemic establishment and cryptic transmission of Zika virus in Brazil and the Americas',\n",
    "'Genomic epidemiology reveals multiple introductions of Zika virus into the United States',\n",
    "'Coinfection With Zika and Dengue-2 Viruses in a Traveler Returning From Haiti, 2016: Clinical Presentation and Genetic Analysis',\n",
    "'Multiplex PCR method for MinION and Illumina sequencing of Zika and other virus genomes directly from clinical samples',\n",
    "'Large returning population of oversea Chinese of Guangdong province combined with tourists increase the risks of ZIKV transmission in Guangdong, China',\n",
    "'Zika Virus Targets Different Primary Human Placental Cells, Suggesting Two Routes for Vertical Transmission',\n",
    "'Establishment and cryptic transmission of Zika virus in Brazil and the Americas',\n",
    "'Zika Virus Outbreak in Haiti in 2014: Molecular and Clinical Data',\n",
    "'Prolonged Detection of Zika Virus in Vaginal Secretions and Whole Blood',\n",
    "'Complete Genome Sequences of Identical Zika virus Isolates in a Nursing Mother and Her Infant',\n",
    "'?',\n",
    "'Zika virus in the Americas: early epidemiological and genetic findings',\n",
    "'Full Genome Sequence and sfRNA Interferon Antagonist Activity of Zika Virus from Recife, Brazil',\n",
    "'Distinct Zika Virus Lineage in Salvador, Bahia, Brazil',\n",
    "'Genome sequence of a candidate World Health Organization reference strain for Zika virus for nucleic acid testing',\n",
    "'Zika virus evolution and spread in the Americas',\n",
    "'Zika virus genome from the Americas',\n",
    "'Complete coding sequence of Zika virus from Martinique outbreak in 2015',\n",
    "'Zika Virus Associated with Microcephaly',\n",
    "'Characterization of a Zika Virus Isolate from Colombia',\n",
    "'Detection and sequencing of Zika virus from amniotic fluid of fetuses with microcephaly in Brazil: a case study',\n",
    "'Phylogeny of Zika Virus in Western Hemisphere, 2015',\n",
    "'Complete genomic sequence of Zika virus isolated from a clinical semen sample',\n",
    "'Infection dynamics in a traveller with persistent shedding of Zika virus RNA in semen for six months after returning from Haiti to Italy, January 2016',                        \n",
    "                  ]\n",
    "\n",
    "published_submissions_with_incorrect_publication_name = [ 'Complete Zika Virus Genome Sequences from a Serum Sample and after Isolation in Vero Cells',\n",
    "'Full coding sequence of the Zika Virus isolate HS-2015-BA-01',\n",
    "'Large returning population of oversea Chinese of Guangdong province combined with tourists increase the risks of ZIKV transmission in Guangdong, China',\n",
    "'The isolation and characterization of Zika virus imported into Guangdong, China',\n",
    "'Full genomic characterization of a Zika virus isolate from Colombia',\n",
    "'Molecular characterization of Zika virus in Mexico',\n",
    "'Repurposed drug candidates to treat ZIKV infection in pregnancy',\n",
    "'Full-genome amplification and sequencing of Zika viruses using a targeted amplification approach',\n",
    "'Zika virus infection with prolonged maternal viremia and fetal brain abnormalities',\n",
    "'Complete genome of Zika virus GZ01 isolate from China',\n",
    "'Complete genomic sequence of Zika virus isolated from a traveler to Colombia in 2016',\n",
    "                                                       \n",
    "                                                         \n",
    "]\n",
    "\n",
    "unpublished_submissions = [\n",
    "'Imported cases of Zika virus disease in Russia in 2016-2017',\n",
    "'Complete Genome of a Zika Virus Isolate, Amazonas, Brazil, 2016',\n",
    "'Imported cases of Zika virus disease in Russia in 2016-2017',\n",
    "'Zika viral sequence identified in Fortaleza, Brazil',\n",
    "'Comparative analysis between the genomes of intra-host and cell cultured Zika virus obtained from a Mexican symptomatic patient'\n",
    "'Zika virus from breast milk',\n",
    "'Genome sequences of Zika viruses isolated in Nicaragua',              \n",
    "'Emergence of Zika virus in Brazil: Detection of Asian genotype',\n",
    "'Brazilian Zika virus genome sequence',\n",
    "'Zika viruses in Haiti during an outbreak of Chikungunya Fever in mid 2014', #white et al sequences\n",
    "'Zika virus sequence from Cuba traveler diagnosed in the United States (Miami, FL)', #nate\n",
    "'Zika virus genomes from human cases in Florida, USA',\n",
    "'Isolation of infectious Zika virus from sera in a traveller returning from Brazil to Italy',\n",
    "'Zika virus infection in pregnant mice',\n",
    "'Zika virus polyprotein sequence isolated from a fetus-brain of Cuba pregnant traveler diagnosed in Spain (Madrid)',\n",
    "'Genome sequences of four Zika virus isolates from Brazil',\n",
    "'Direct Submission'\n",
    "                          ]\n",
    "\n",
    "unpublished_seqs_to_pursue = [\n",
    "                              'Genome sequences of Zika viruses isolated in Nicaragua',\n",
    "                              'Imported cases of Zika virus disease in Russia in 2016-2017', #dominican republic and mexico\n",
    "                              'Zika viruses in Haiti during an outbreak of Chikungunya Fever in mid 2014',\n",
    "                              'Zika virus polyprotein sequence isolated from a fetus-brain of Cuba pregnant traveler diagnosed in Spain (Madrid)', #cuba\n",
    "                              'Genome sequences of four Zika virus isolates from Brazil' #brazil early...published on, but not by the submitting authors... \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "published_fauna_seqs = {key:value for key,value in fauna_dict.items() if fauna_dict[key].description.split('|')[12] in published_submissions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/published-sequences-in-analysis.tsv','w') as file:\n",
    "    file.write('{}\\t{}\\t{}\\n'.format('strain_name', 'accession_number', 'lead_author'))\n",
    "    for key in published_fauna_seqs.keys():\n",
    "        file.write('{}\\t{}\\t{}\\n'.format(key.split('|')[0], key.split('|')[2], key.split('|')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(published_fauna_seqs)\n",
    "\n",
    "with open('/Users/alliblk/Desktop/gitrepos/zika-usvi/data/fastas/augur-published-seqs-only.fasta','w') as file:\n",
    "    for key in published_fauna_seqs.keys():\n",
    "        if published_fauna_seqs[key].description.split('|')[4] in regions_to_exclude1: #don't write out anything except American seqs:\n",
    "            continue\n",
    "        else: \n",
    "            file.write(str('>' + published_fauna_seqs[key].description + '\\n' + published_fauna_seqs[key].seq + '\\n'))\n",
    "    file.write(str('>' + published_fauna_seqs['PF13/251013_18|zika|KX369547|2013-10-25|oceania|french_polynesia|french_polynesia|french_polynesia|genbank|genome|Troesemeier'].description+ '\\n' + published_fauna_seqs[key].seq + '\\n'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
